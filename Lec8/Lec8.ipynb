{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture 8: Statistical Analysis with `scipy.stats`\n",
        "\n",
        "## Introduction\n",
        "\n",
        "The `scipy.stats` module in SciPy is a cornerstone for statistical analysis in Python, offering a broad spectrum of functions for probability distributions, statistical tests, and descriptive statistics. This comprehensive lecture note will delve into the functionalities provided by `scipy.stats`, illustrated with detailed examples to facilitate a deeper understanding of statistical analysis in scientific computing.\n",
        "\n",
        "## 1. Understanding Probability Distributions\n",
        "\n",
        "### 1.1 Continuous Distributions\n",
        "\n",
        "- **Normal Distribution**: Central to many statistical analyses, described by its mean (μ) and standard deviation (σ).\n",
        "\n",
        "```python\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Parameters\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Parameters\n",
        "mu, sigma = 0, 1\n",
        "\n",
        "# Points\n",
        "x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n",
        "\n",
        "# Plot\n",
        "plt.plot(x, norm.pdf(x, mu, sigma))\n",
        "plt.plot(x, norm.cdf(x, mu, sigma))\n",
        "plt.title('Normal Distribution')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('PDF')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# PDF and CDF\n",
        "pdf_val = norm.pdf(0, mu, sigma)\n",
        "cdf_val = norm.cdf(0, mu, sigma)\n",
        "\n",
        "print(f\"PDF at x=0: {pdf_val}\")\n",
        "print(f\"CDF at x=0: {cdf_val}\")\n",
        "```\n",
        "\n",
        "- **Exponential Distribution**: Models the time until an event occurs, with rate parameter λ.\n",
        "\n",
        "```python\n",
        "from scipy.stats import expon\n",
        "\n",
        "lambda_inv = 1  # Mean of exponential distribution, λ^-1\n",
        "exp_dist = expon(scale=lambda_inv)\n",
        "\n",
        "print(f\"PDF at x=1: {exp_dist.pdf(1)}\")\n",
        "```\n",
        "\n",
        "### 1.2 Discrete Distributions\n",
        "\n",
        "- **Binomial Distribution**: Describes the number of successes in n independent Bernoulli trials, with success probability p.\n",
        "\n",
        "```python\n",
        "from scipy.stats import binom\n",
        "\n",
        "n, p = 10, 0.5  # 10 trials, success probability 0.5\n",
        "binom_dist = binom(n, p)\n",
        "\n",
        "print(f\"PMF for 5 successes: {binom_dist.pmf(5)}\")\n",
        "```\n",
        "\n",
        "## 2. Descriptive Statistics\n",
        "\n",
        "`scipy.stats` offers functions to describe and summarize the central tendency, dispersion, and shape of datasets.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "data = np.random.normal(mu, sigma, 1000)\n",
        "\n",
        "# Central tendency\n",
        "mean = np.mean(data)\n",
        "median = np.median(data)\n",
        "\n",
        "# Dispersion\n",
        "std_dev = np.std(data)\n",
        "variance = np.var(data)\n",
        "\n",
        "# Shape\n",
        "skewness = stats.skew(data)\n",
        "kurtosis = stats.kurtosis(data)\n",
        "\n",
        "print(f\"Mean: {mean}, Median: {median}, Std Dev: {std_dev}, Variance: {variance}\")\n",
        "print(f\"Skewness: {skewness}, Kurtosis: {kurtosis}\")\n",
        "\n",
        "# or\n",
        "datastats = stats.describe(data)\n",
        "print(datastats)\n",
        "\n",
        "```\n",
        "\n",
        "## 3. Hypothesis Testing\n",
        "\n",
        "Hypothesis tests are critical for making inferences about populations from sample data. `scipy.stats` includes functions for conducting various statistical tests.\n",
        "\n",
        "### 3.1 T-tests\n",
        "\n",
        "- **One-sample T-test**: Tests if the mean of a sample differs from a known value.\n",
        "\n",
        "```python\n",
        "# Testing if sample mean differs from true mean of 0\n",
        "mu, sigma = 0, 1\n",
        "data = np.random.normal(mu, sigma, 1000)\n",
        "t_stat, p_val = stats.ttest_1samp(data, 0)\n",
        "\n",
        "print(f\"One-sample T-test: T-stat={t_stat}, P-value={p_val}\")\n",
        "```\n",
        "\n",
        "### 3.2 ANOVA (Analysis of Variance)\n",
        "\n",
        "- **One-way ANOVA**: Tests if there are statistically significant differences between the means of three or more independent groups.\n",
        "\n",
        "```python\n",
        "data1 = np.random.normal(mu, sigma, 100)\n",
        "data2 = np.random.normal(mu, sigma, 100)\n",
        "data3 = np.random.normal(mu, sigma, 100)\n",
        "\n",
        "f_val, p_val = stats.f_oneway(data1, data2, data3)\n",
        "\n",
        "print(f\"ANOVA: F-statistic={f_val}, P-value={p_val}\")\n",
        "```\n",
        "\n",
        "## 4. Correlation and Regression\n",
        "\n",
        "Correlation measures the relationship between two variables, while regression models the dependence of a variable on one or more other variables.\n",
        "\n",
        "### 4.1 Pearson Correlation Coefficient\n",
        "\n",
        "```python\n",
        "x = np.random.random(100)\n",
        "y = 2*x + np.random.normal(0, 1, 100)\n",
        "\n",
        "corr_coef, p_val = stats.pearsonr(x, y)\n",
        "\n",
        "print(f\"Pearson Correlation Coefficient: {corr_coef}, P-value: {p_val}\")\n",
        "```\n",
        "\n",
        "### 4.2 Linear Regression\n",
        "\n",
        "```python\n",
        "slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
        "\n",
        "print(f\"Linear Regression: Slope={slope}, Intercept={intercept}, R-squared={r_value**2}\")\n",
        "```\n",
        "\n",
        "## 5 Testing normality\n",
        "Testing whether a dataset follows a normal distribution is a common task in statistical analysis. The `scipy.stats` module provides several tests for this purpose, including the Shapiro-Wilk test. Such tests evaluate the hypothesis that a dataset comes from a normally distributed population.\n",
        "\n",
        "### Shapiro-Wilk Test\n",
        "\n",
        "The Shapiro-Wilk test is widely used for testing normality due to its good power properties as compared to other tests. It works well for small sample sizes (< 50 samples), but can also be applied to larger datasets.\n",
        "\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Generate sample data\n",
        "data = np.random.normal(loc=0, scale=1, size=100)\n",
        "\n",
        "# Perform the Shapiro-Wilk test for normality\n",
        "shapiro_test_stat, shapiro_p_value = stats.shapiro(data)\n",
        "\n",
        "print(\"Shapiro-Wilk Test Statistic:\", shapiro_test_stat)\n",
        "print(\"Shapiro-Wilk Test P-Value:\", shapiro_p_value)\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if shapiro_p_value > alpha:\n",
        "    print(\"Sample looks Gaussian (fail to reject H0)\")\n",
        "else:\n",
        "    print(\"Sample does not look Gaussian (reject H0)\")\n",
        "```\n",
        "\n",
        "### Visual Inspection\n",
        "\n",
        "In addition to statistical tests, visual inspection with QQ-plots (quantile-quantile plots) and histograms can be helpful to assess normality.\n",
        "\n",
        "#### QQ-Plot Example:\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Generate QQ plot\n",
        "fig = plt.figure()\n",
        "res = stats.probplot(data, plot=plt)\n",
        "\n",
        "plt.title(\"QQ Plot\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "#### Histogram Example:\n",
        "\n",
        "```python\n",
        "# Plot histogram\n",
        "plt.hist(data, bins=20, alpha=0.7, color='blue', edgecolor='black')\n",
        "plt.title(\"Histogram of the Data\")\n",
        "plt.xlabel(\"Value\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "## 6 Box-Cox Transformation\n",
        "The Box-Cox transformation is a statistical technique used to stabilize variance and make the data more closely resemble a normal distribution.\n",
        "\n",
        "Many statistical methods and techniques assume that the data follows a normal distribution. However, real-world data often deviates from this assumption. The Box-Cox transformation is a powerful method for transforming non-normal dependent variables into a normal shape.\n",
        "\n",
        "### Mathematical Formulation\n",
        "\n",
        "The Box-Cox transformation is defined as:\n",
        "\n",
        "\\[\n",
        "y(\\lambda) = \\begin{cases}\n",
        "\\frac{y^\\lambda - 1}{\\lambda} & \\text{if } \\lambda \\neq 0 \\\\\n",
        "\\log(y) & \\text{if } \\lambda = 0\n",
        "\\end{cases}\n",
        "\\]\n",
        "\n",
        "where:\n",
        "- \\(y\\) is the response variable that needs to be transformed.\n",
        "- \\(\\lambda\\) is the transformation parameter that varies to find the best approximation to a normal distribution.\n",
        "\n",
        "### Determining the Best \\(\\lambda\\)\n",
        "\n",
        "The value of \\(\\lambda\\) that best normalizes the data is determined through maximum likelihood estimation.\n",
        "\n",
        "### Implementation in Python\n",
        "\n",
        "The `scipy.stats` module provides the `boxcox` function, which automatically finds the optimal \\(\\lambda\\) value and applies the Box-Cox transformation.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate non-normal data\n",
        "data = np.random.exponential(size=1000)\n",
        "\n",
        "# Apply Box-Cox Transformation\n",
        "transformed_data, best_lambda = stats.boxcox(data)\n",
        "\n",
        "print(f\"Optimal λ value: {best_lambda}\")\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Original Data\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(data, bins=30, alpha=0.7, color='blue')\n",
        "plt.title(\"Original Data\")\n",
        "\n",
        "# Transformed Data\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(transformed_data, bins=30, alpha=0.7, color='green')\n",
        "plt.title(\"Box-Cox Transformed Data\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### Applications\n",
        "\n",
        "- **Improving Linear Model Fit**: The Box-Cox transformation can be applied to the dependent variable in regression analyses to meet the normality assumption.\n",
        "- **Variance Stabilization**: It is useful for stabilizing the variance of a dataset, as many statistical techniques assume homoscedasticity (constant variance).\n",
        "- **Data Preprocessing**: In machine learning, transforming features to more closely follow a Gaussian distribution can improve the performance of models.\n",
        "\n",
        "### Considerations\n",
        "\n",
        "- The Box-Cox transformation requires all data to be positive. If the dataset contains zero or negative values, a constant may be added to all values to make them strictly positive before applying the transformation.\n",
        "- It's important to apply the same transformation to new data before using a model that was trained on transformed data.\n",
        "\n",
        "## 6. Practical Applications\n",
        "\n",
        "- Use `scipy.stats` to print out the statistics of the GPP column in Wcr_GPPdaily.csv.\n",
        "- Apply linregress for a linear regression model between `GPP_NT_VUT_REF` and the meterological factors\n"
      ],
      "metadata": {
        "id": "UQUh0rDge2iH"
      }
    }
  ]
}