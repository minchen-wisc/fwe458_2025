{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Lecture 14 Fundamentals of Machine Learning**\n",
        "\n",
        "Recommended readings:\n",
        "**The Hundred-page Machine Learning book**\n",
        "https://github.com/tirthajyoti/Papers-Literature-ML-DL-RL-AI/blob/master/General-Machine-Learning/The%20Hundred-Page%20Machine%20Learning%20Book%20by%20Andriy%20Burkov/Links%20to%20read%20the%20chapters%20online.md\n",
        "\n",
        "## 1. What is Machine Learning\n",
        "Algorithm building which relies on a collection of examples of some phenomenon.\n",
        "\n",
        "- gathering a dataset\n",
        "- algorithmically building a statistical model based on that dataset\n",
        "\n",
        "### Types of Learning\n",
        "![picture](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6iDmbHflsN6NULBLpVHA6A.png)\n",
        "\n",
        "### Supervised Machine Learning\n",
        "### Supervised Machine Learning\n",
        "\n",
        "The supervised learning process starts with gathering a paired dataset, with N labeled examples\n",
        "\n",
        "$$\n",
        "{<\\pmb{x_i}, y_i>}, i \\in N\n",
        "$$\n",
        "\n",
        "$\\pmb{x_i}$ is a vector, called feature vector. Each feature vector has a length of M, representing M \"features\" of a object.\n",
        "\n",
        "${y_i}$ is call \"label\", can be a class or a real number\n",
        "\n",
        "For example, we could have a labelled dataset of human heart health:\n",
        "\n",
        "Sex, Age, Weight, Blood pressre, low density cholesterol, high density cholesterol, diet habit, smoke or not, alchhol or not, risk level\n",
        "\n",
        "What is $\\pmb{x_i}$ in this example?\n",
        "What is $y_i$ in this example?\n",
        "\n",
        "#### In Supervised Learning, the dataset is the collection of labeled examples; The goal of a supervised learning algorithm is to use the dataset to produce a model that takes a feature vector x as input and outputs information that allows deducing the label for this feature vector.\n",
        "\n",
        "- Classification: Classification is the task of predicting a discrete class label.\n",
        "- Regression: Regression is the task of predicting a continuous quantity.\n",
        "\n",
        "### Unsupervised Machine Learning\n",
        "\n",
        "The supervised learning process starts with gathering a dataset, with N unlabeled examples\n",
        "\n",
        "$$\n",
        "{\\pmb{x_i}}, i \\in N\n",
        "$$\n",
        "\n",
        "$\\pmb{x_i}$ is also a feature vector. Each feature vector has a length of M, representing M \"features\" of a object.\n",
        "\n",
        "#### In Unsupervised Learning, the dataset is the collection of unlabeled examples; the goal of an unsupervised learning algorithm is to create a model that takes a feature vector x as input and either transforms it into another vector or into a value that can be used to solve a practical problem.\n",
        "\n",
        "\n",
        "### Reinforcement Learning\n",
        "#### The goal of a reinforcement learning algorithm is to learn a policy.\n",
        "The machine is trained to make specific decisions. It works this way: the machine is exposed to an environment where it trains itself continually using trial and error. This machine learns from past experience and tries to capture the best possible knowledge to make accurate business decisions. Example of Reinforcement Learning: Markov Decision Process.\n",
        "\n",
        "## 2. Commonly used Machine Learning algorithms\n",
        "1) linear regression \\\n",
        "2) logistic regression \\\n",
        "3) Supporting Vector Machine \\\n",
        "4) Decision Tree \\\n",
        "5) KNN \\\n",
        "6) K-Means \\\n",
        "7) Random Forest \\\n",
        "8) Artificial Neural Network\n",
        "\n",
        "and many ...\n",
        "\n",
        "### 2.1 Linear regression\n",
        "In linear regression problems, the goal is to predict a real-value variable $y$ from a given feature $X$.\\\n",
        "In the case of linear regression the output is a linear function of the input. Let $ŷ$ be the output our model predicts:\n",
        "$$\n",
        "ŷ = WX+b\n",
        "$$\n",
        "Here $X$ is a vector (features of an example), $W$ are the weights (vector of parameters) that determine how each feature affects the prediction andb is bias term. So our task is to predict $y$ from $X$, now we need to measure performance $P$ to know how well the model performs.\\\n",
        "Now to calculate the performance of the model, we first calculate the error of each example $i$ as:\n",
        "$$\n",
        "err_i = abs(ŷ-y)\n",
        "$$\n",
        "we take the absolute value of the error to take into account both positive and negative values of error.\n",
        "Finally we calculate the mean for all recorded absolute errors (Average sum of all absolute errors).\n",
        "Mean Absolute Error (MAE) = Average of All absolute errors\n",
        "$$\n",
        "MAE = \\frac{1}{m}\\sum \\limits_i abs(ŷ_i-y_i)\n",
        "$$\n",
        "More popular way of measuring model performance is using\n",
        "Mean Squared Error (MSE): Average of squared differences between prediction and actual observation.\n",
        "$$\n",
        "MSE=\\frac{1}{2m}\\sum \\limits_i (ŷ_i-y_i)^2\n",
        "$$\n",
        "The mean is halved (1/2) as a convenience for the computation of the gradient descent, as the derivative term of the square function will cancel out the 1/2 term.\n",
        "The main aim of training the ML algorithm is to adjust the weights W to reduce the MAE or MSE.\n",
        "To minimize the error, the model while experiencing the examples of the training set, updates the model parameters W. These error calculations when plotted against the W is also called cost function J(w), since it determines the cost/penalty of the model. So minimizing the error is also called as minimization the cost function J."
      ],
      "metadata": {
        "id": "zHsFKyh3LVzl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Logistic regression\n",
        "\n",
        "**Logistic regression is not a regression!**\n",
        "\n",
        "It is a classification learning algorithm. The name comes from statistics and is due to the fact that the mathematical formulation of logistic regression is similar to that of linear regression.\n",
        "\n",
        "In Logistic regression, we still want to model y as a linear function of X. But for classification problem, e.g., y is binary (0 or 1), a linear function is not straightfoward because the resulted y prediction could be a continuous number ranging from negative to positive.\n",
        "\n",
        "At the time where the absense of computers required scientists to perfrom manual calculations, they were eager to find a linear classification model. They figured out that if we define a negative label as 0 and the positive label as 1, we would just need to find a simple continuous function whose codomain is (0,1). In such a case, if the value returned by the model for input $\\pmb{X}$ is closer to 0, then we assign a negative label to $\\pmb{X}$; otherwise, the example is labeled as positive. One function has such a property is the standard logistic function, also known as the sigmoid function:\n",
        "\n",
        "$$\n",
        "f(x)=\\frac{1}{1+e^{-x}}\n",
        "$$\n",
        "\n",
        "And the logistic regression model looks like:\n",
        "\n",
        "$$\n",
        "f_{\\pmb{W},\\pmb{b}}(\\pmb{X})=\\frac{1}{1+e^{-\\pmb{WX+b}}}\n",
        "$$\n",
        "\n",
        "By looking at the graph of the standard logistic function, we can see how well it fits our classification purpose: if we optimize the values of $\\pmb{W}$ and b appropriately, we could interpret the output of f(x) as the probablity of $y_i$ being positive; For example, if it is higher than or equal to the threshold 0.5 we would say that the class of X is positive; otherwise it is negative. In practice, the choice of the threshold could be different depending on the problem.\n",
        "\n",
        "For example: If the output is 0.75, we can say in terms of probability as: There is a 75 percent chance that ...\n",
        "\n"
      ],
      "metadata": {
        "id": "Mz220WrwNQUQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To summarize:\n",
        "\n",
        "#### Linear Regression\n",
        "\n",
        "**Concept:** Linear Regression is used to model the relationship between a dependent variable (Y) and one or more independent variables (X) by fitting a linear equation to observed data. The simplest form is simple linear regression, which deals with a single independent variable, and the relationship is modeled as a straight line.\n",
        "\n",
        "**Use Cases:** It is typically used for predicting a continuous variable, such as predicting house prices based on their size, predicting salaries based on experience, etc.\n",
        "\n",
        "#### Logistic Regression\n",
        "\n",
        "**Concept:** Logistic Regression, despite its name, is used for classification problems, not regression. It predicts the probability that a given input belongs to a certain category. The outcome is binary or dichotomous, i.e., 1/0, Yes/No, True/False. The core idea is to use the logistic function to model the probability that a certain instance belongs to a particular class\n",
        "\n",
        "**Use Cases:** It is used for binary classification tasks, such as spam detection (spam/not spam), disease diagnosis (sick/healthy), etc.\n",
        "\n",
        "### Similarities\n",
        "\n",
        "- **Modeling Relationship:** Both are used to model the relationship between one or more independent variables and a dependent variable.\n",
        "- **Coefficient Estimation:** In both, coefficients are estimated using the maximum likelihood estimation (MLE) method.\n",
        "\n",
        "### Differences\n",
        "\n",
        "- **Outcome Type:** Linear regression is used for predicting continuous outcomes, while logistic regression is used for binary classification tasks.\n",
        "- **Function:** Linear regression involves fitting a linear equation to the observed data, whereas logistic regression uses a logistic function to model the probability of belonging to a default class.\n",
        "- **Interpretation of Outputs:** The output of a linear regression model is a continuous value, while the output of a logistic regression model is a probability that is used to classify the observations."
      ],
      "metadata": {
        "id": "FpZRMtXLO7G9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. scikit-learn\n",
        "`scikit-learn` (often imported as `sklearn`) is a powerful and versatile Python library used for machine learning. It provides a wide range of supervised and unsupervised learning algorithms, tools for model fitting, data preprocessing, model selection, and evaluation, all through a consistent interface. One of its strengths is the simplicity with which you can implement complex machine learning models.\n",
        "\n",
        "Using `scikit-learn` to build and test a machine learning model involves several common steps. These steps form a workflow that ensures a systematic approach to model development, from data preparation to model evaluation. Here’s a typical workflow:\n",
        "\n",
        "### Import Required Libraries\n",
        "\n",
        "Start by importing the necessary libraries and modules. Common imports include `numpy`, `pandas` for data manipulation, and various modules from `scikit-learn` for model building and evaluation.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "```\n",
        "\n",
        "### Load and Explore the Dataset\n",
        "\n",
        "Load your dataset, often into a Pandas DataFrame, and perform exploratory data analysis to understand its structure, features, and labels.\n",
        "\n",
        "```python\n",
        "data = pd.read_csv('dataset.csv')\n",
        "data.head()  # Display the first few rows\n",
        "```\n",
        "\n",
        "### Preprocess the Data\n",
        "\n",
        "Data preprocessing steps may include handling missing values, encoding categorical variables, feature scaling, and feature selection.\n",
        "\n",
        "- **Handling missing values** can be done by imputing values or dropping rows/columns.\n",
        "- **Encoding categorical variables** is necessary because most machine learning models expect numerical input. Common strategies include one-hot encoding or label encoding.\n",
        "- **Feature scaling** (standardization or normalization) is crucial for many algorithms to perform well.\n",
        "\n",
        "```python\n",
        "# Example of feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "```\n",
        "\n",
        "### Split the Data into Training and Test Sets\n",
        "\n",
        "Split your dataset into a training set and a test set. This is crucial for evaluating your model's performance on unseen data.\n",
        "\n",
        "```python\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "```\n",
        "\n",
        "### Choose a Model\n",
        "\n",
        "`scikit-learn` offers a variety of models for both supervised and unsupervised learning tasks. The choice of model depends on the problem at hand (e.g., regression, classification, clustering).\n",
        "\n",
        "```python\n",
        "model = LogisticRegression()\n",
        "```\n",
        "\n",
        "### Train the Model\n",
        "\n",
        "Fit the model to your training data using the `fit` method. This step involves the model learning from the input features and their corresponding targets.\n",
        "\n",
        "```python\n",
        "model.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "### Make Predictions\n",
        "\n",
        "Use the trained model to make predictions on the test set (or any new data).\n",
        "\n",
        "```python\n",
        "predictions = model.predict(X_test)\n",
        "```\n",
        "\n",
        "### Evaluate the Model\n",
        "\n",
        "Evaluate your model's performance using appropriate metrics. Common metrics include accuracy, precision, recall, F1 score for classification tasks, and mean squared error (MSE) or R-squared for regression tasks.\n",
        "\n",
        "```python\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "```\n",
        "\n",
        "### Model Improvement\n",
        "\n",
        "Based on the performance metrics, you may need to go back and try different preprocessing steps, choose a different model, or tune your model's hyperparameters using techniques like cross-validation or grid search.\n",
        "\n",
        "### Finalize Your Model\n",
        "\n",
        "Once satisfied with the model's performance, it can be finalized. This might include retraining on the entire dataset or simply proceeding with the current trained model.\n",
        "\n",
        "### Save/Load the Model\n",
        "\n",
        "For future use, you can save your trained model to a file and load it when needed.\n",
        "\n",
        "```python\n",
        "from joblib import dump, load\n",
        "dump(model, 'model.joblib')  # Save\n",
        "model = load('model.joblib')  # Load\n",
        "```"
      ],
      "metadata": {
        "id": "aJxuAzsyPXd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code source: Jaques Grobler\n",
        "# License: BSD 3 clause\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load the diabetes dataset\n",
        "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)\n",
        "\n",
        "# Use only one feature\n",
        "diabetes_X = diabetes_X[:, np.newaxis, 2]\n",
        "\n",
        "# Split the data into training/testing sets\n",
        "diabetes_X_train = diabetes_X[:-20]\n",
        "diabetes_X_test = diabetes_X[-20:]\n",
        "\n",
        "# Split the targets into training/testing sets\n",
        "diabetes_y_train = diabetes_y[:-20]\n",
        "diabetes_y_test = diabetes_y[-20:]\n",
        "\n",
        "# Create linear regression object\n",
        "regr = LinearRegression()\n",
        "\n",
        "# Train the model using the training sets\n",
        "regr.fit(diabetes_X_train, diabetes_y_train)\n",
        "\n",
        "# Make predictions using the testing set\n",
        "diabetes_y_pred = regr.predict(diabetes_X_test)\n",
        "\n",
        "# The coefficients\n",
        "print(\"Coefficients: \\n\", regr.coef_)\n",
        "# The mean squared error\n",
        "print(\"Mean squared error: %.2f\" % mean_squared_error(diabetes_y_test, diabetes_y_pred))\n",
        "# The coefficient of determination: 1 is perfect prediction\n",
        "print(\"Coefficient of determination: %.2f\" % r2_score(diabetes_y_test, diabetes_y_pred))\n",
        "\n",
        "# Plot outputs\n",
        "plt.scatter(diabetes_X_test, diabetes_y_test, color=\"black\")\n",
        "plt.plot(diabetes_X_test, diabetes_y_pred, color=\"blue\", linewidth=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "r8KycWBfR59f",
        "outputId": "78531144-65bf-4928-8c0d-c9041a6dece8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: \n",
            " [938.23786125]\n",
            "Mean squared error: 2548.07\n",
            "Coefficient of determination: 0.47\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x79b4ce809150>]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA8f0lEQVR4nO3dfXRU9b3v8c8wQHjMxIAhCRPEh4KAgB5UTG0QBHkQKhpyrIgWLEsqDW0QjxdprR69ruLx4UqkKvZeqz1V0BoHabVoERKMGhDpQUGEAo0SQhKoSAIIIUx+948xAwMBZiezM3sm79das3T27D3z/RnMfPg9bZcxxggAAMBB2kS7AAAAgJMRUAAAgOMQUAAAgOMQUAAAgOMQUAAAgOMQUAAAgOMQUAAAgOMQUAAAgOO0jXYBTVFfX6/du3era9eucrlc0S4HAACEwRijAwcOKD09XW3anLmPJCYDyu7du5WRkRHtMgAAQBOUlZXJ6/We8ZyYDChdu3aVFGhgYmJilKsBAADhqKmpUUZGRvB7/ExiMqA0DOskJiYSUAAAiDHhTM9gkiwAAHAcAgoAAHAcAgoAAHAcAgoAAHAcAgoAAHAcAgoAAHAcAgoAAHAcAgoAAHCcmNyoDQAA2MPv96u4uFgVFRVKS0tTVlaW3G53i9dBQAEAAJIkn8+nvLw87dq1K3jM6/UqPz9f2dnZLVoLQzwAAEA+n085OTkh4USSysvLlZOTI5/P16L1EFAAAGjl/H6/8vLyZIw55bWGY7Nnz5bf72+xmggoAAC0csXFxaf0nJzIGKOysjIVFxe3WE0EFAAAWrmKioqInhcJBBQAAFq5tLS0iJ4XCQQUAABauaysLHm9XrlcrkZfd7lcysjIUFZWVovVREABAKCVc7vdys/Pl6RTQkrD8wULFrTofigEFAAAoOzsbBUUFKhnz54hx71erwoKClp8HxSXaWxNkcPV1NTI4/GourpaiYmJ0S4HAIC4YedOsla+v9lJFgAABLndbg0fPjzaZTDEAwAAnIeAAgAAHMdSQHnuuec0aNAgJSYmKjExUZmZmVq+fHnw9SNHjig3N1fdunVTly5dNGnSJFVVVYW8x86dOzV+/Hh16tRJKSkpuvfee3Xs2LHItAYAAMQFSwHF6/Xq0Ucf1fr16/XJJ5/o2muv1cSJE/X5559Lku6++2795S9/0euvv67Vq1dr9+7dIbN+/X6/xo8fr6NHj+qjjz7SH/7wB7300kt64IEHItsqAAAQ05q9iic5OVmPP/64cnJydO6552rx4sXKycmRJG3ZskX9+vVTSUmJrrrqKi1fvlwTJkzQ7t271aNHD0nSokWLNHfuXO3du1ft27cP6zNZxQMAQOyx8v3d5Dkofr9fr776qg4dOqTMzEytX79edXV1GjVqVPCciy++WL169VJJSYkkqaSkRAMHDgyGE0kaM2aMampqgr0wjamtrVVNTU3IAwAAxC/LAWXjxo3q0qWLEhISdNddd2np0qXq37+/Kisr1b59eyUlJYWc36NHD1VWVkqSKisrQ8JJw+sNr53O/Pnz5fF4go+MjAyrZQMAgBhiOaD07dtXGzZs0Nq1azVz5kxNnTpVmzdvtqO2oHnz5qm6ujr4KCsrs/XzAABAdFneqK19+/a66KKLJElDhgzRunXrlJ+frx/96Ec6evSo9u/fH9KLUlVVpdTUVElSamqqPv7445D3a1jl03BOYxISEpSQkGC1VAAAEKOavQ9KfX29amtrNWTIELVr104rV64MvrZ161bt3LlTmZmZkqTMzExt3LhRe/bsCZ6zYsUKJSYmqn///s0tBQAAxAlLPSjz5s3TuHHj1KtXLx04cECLFy9WUVGR3n33XXk8Hk2fPl1z5sxRcnKyEhMT9fOf/1yZmZm66qqrJEmjR49W//79dfvtt+uxxx5TZWWl7r//fuXm5tJDAgAAgiwFlD179ujHP/6xKioq5PF4NGjQIL377ru67rrrJElPPfWU2rRpo0mTJqm2tlZjxozRs88+G7ze7Xbrrbfe0syZM5WZmanOnTtr6tSpevjhhyPbKgAAENO4mzEAAGgRLbIPCgAAgF0IKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEIKAAAwHEsBZT58+friiuuUNeuXZWSkqIbb7xRW7duDTln+PDhcrlcIY+77ror5JydO3dq/Pjx6tSpk1JSUnTvvffq2LFjzW8NAACIC22tnLx69Wrl5ubqiiuu0LFjx/TLX/5So0eP1ubNm9W5c+fgeXfeeacefvjh4PNOnToF/93v92v8+PFKTU3VRx99pIqKCv34xz9Wu3bt9Jvf/CYCTQIAALHOZYwxTb147969SklJ0erVqzVs2DBJgR6USy+9VAsWLGj0muXLl2vChAnavXu3evToIUlatGiR5s6dq71796p9+/Zn/dyamhp5PB5VV1crMTGxqeUDAIAWZOX7u1lzUKqrqyVJycnJIcdfeeUVde/eXZdcconmzZunb7/9NvhaSUmJBg4cGAwnkjRmzBjV1NTo888/b/RzamtrVVNTE/IAAADxy9IQz4nq6+s1e/ZsXX311brkkkuCx2+99Vadd955Sk9P12effaa5c+dq69at8vl8kqTKysqQcCIp+LyysrLRz5o/f74eeuihppYKAABiTJMDSm5urjZt2qQPPvgg5PiMGTOC/z5w4EClpaVp5MiR2rFjhy688MImfda8efM0Z86c4POamhplZGQ0rXAAAOB4TRrimTVrlt566y0VFhbK6/We8dyhQ4dKkrZv3y5JSk1NVVVVVcg5Dc9TU1MbfY+EhAQlJiaGPAAAQPyyFFCMMZo1a5aWLl2qVatW6fzzzz/rNRs2bJAkpaWlSZIyMzO1ceNG7dmzJ3jOihUrlJiYqP79+1spBwAAxClLQzy5ublavHixli1bpq5duwbnjHg8HnXs2FE7duzQ4sWLdf3116tbt2767LPPdPfdd2vYsGEaNGiQJGn06NHq37+/br/9dj322GOqrKzU/fffr9zcXCUkJES+hQAAIOZYWmbscrkaPf7iiy9q2rRpKisr02233aZNmzbp0KFDysjI0E033aT7778/ZFjmq6++0syZM1VUVKTOnTtr6tSpevTRR9W2bXh5iWXGAADEHivf383aByVaCCgAAMSeFtsHBQAAwA4EFAAA4DgEFAAA4DgEFAAA4DgEFAAA4DgEFAAA4DgEFAAA4DgEFAAA4DgEFAAA4DgEFAAAIEkqKpJcrsCja1fp22+jVwsBBQAAB/L7/SoqKtKSJUtUVFQkv99vy+cYI/3v/x0IJSNGHD9+8KA0bpwtHxkWS3czBgAA9vP5fMrLy9OuXbuCx7xer/Lz85WdnR2Rz6iuliZOlFavPv05778fkY9qEnpQAABwEJ/Pp5ycnJBwIknl5eXKycmRz+dr1vv//e+B3pKkpDOHE0n64x+b9VHNQkABAMAh/H6/8vLyZIw55bWGY7Nnz27ScM9zzwWCyZAh4Z3//vvSbbdZ/piIIaAAAOAQxcXFp/ScnMgYo7KyMhUXF4f1focPSzk5gWDys5+d/fwLL5R27QrMS8nKCrdqexBQAABwiIqKioict22bdM45UqdO0htvnP39ZsyQ6uqk7dulnj3DKsF2BBQAABwiLS2tWef96U+B3pI+faT9+8/+Pq++Gugtef55qa3Dls0QUAAAcIisrCx5vV65XK5GX3e5XMrIyFDWCeMvx45JM2cGgsmPfnT2z0hMlLZsCQSTcM6PFgIKAAAO4Xa7lZ+fL0mnhJSG5wsWLJDb7dbu3dL3vie1ayctWnT2987ODmy8Vl0t9e0b8dIjjoACAICDZGdnq6CgQD1Pmgzi9XpVUFCgxMRsuVyBuSLbt5/9/Z55JtBb8sYbUseONhVtA5dpbC2Tw9XU1Mjj8ai6ulqJiYnRLgcAgIjz+/0qLi5WRUWFUlPT9N57w/Sb34Tfr/DJJ+EvKW4pVr6/HTYlBgAASIHhnj59hodsP382w4ZJy5YFNmGLdQzxAADgMEuXKjiME46HHpLq6wM7w8ZDOJHoQQEAwDFuvVVasiT881eulK691r56oomAAgBAFFVXW+v16N8/EExSU20ryREY4gEAIAqKi4/ftC8co0YF9jz5/PP4DycSAQUAgBZ1332BYDJsWHjnP/JIYJnwihWS221vbU7CEA8AtBInLltNS0tTVlaW3K3pGy+KjhwJTHjdty/8a9atky6/3L6anI6AAgCtgM/nU15eXsidcr1er/Lz85WdnR3FyuLbpk3SwIHhn9+unfTNN1LnzvbVFCsY4gGAOOfz+ZSTkxMSTiSpvLxcOTk58vl8Uaosfj39dGAYJ9xwctddgWGco0cJJw3YSRYA4pjf71fv3r1PCScNXC6XvF6vSktLGe5pJr8/MCSzYUP417z7rjR6tG0lOY6V7296UAAgjhUXF582nEiSMUZlZWUqLi5uwariS1lZoLekbdvww8nevYEek9YUTqwioABAHKuoqIjoeTjutdcCwaRXr/DOv/76wG6vxkjdu9tbWzwgoABAHEtLS4voea2dMdKNNwaCyS23hHfNyy8Hrnv77cB1CA+reAAgjmVlZcnr9aq8vFyNTTlsmIOSlZUVhepix759Urdu1q755z+l88+3p57WgB4UAIhjbrdb+fn5kgJh5EQNzxcsWMAE2dNYtSrQ6xFuOLnkksBur8YQTpqLgAIAcS47O1sFBQXqedKtcb1erwoKCtgHpRF5eYFgMnJkeOc/8UQglGzc2Lp2e7UTy4wBoJVgJ9kz+/bbwOTVw4fDv2bDBmnwYNtKijtWvr+ZgwIArYTb7dbw4cOjXYbjbNggXXZZ+OcnJkqVlVLHjraVBDHEAwBopR57LDCME244mT07MIxTXU04aQn0oAAAWo1jxwLbz2/ZEv41q1ZJI0bYVxMaR0ABAMS90lLpggusXbNvn3TOOfbUg7NjiAcAELf++MfAME644WTSpOO7vRJOooseFABAXDFGGjcucCO+cP3pT9K//7t9NcE6AgoAIC7s3SulpFi7ZudOKSPDnnrQPAzxAABi2jvvBIZxwg0nV1wh+f2BnhbCiXMRUAAAMemnPw0Ek3Hjwjt/4cJAKPn4Y6kN336OxxAPACBmHDwode1q7ZpNm6QBA+ypB/YhQwIAHG/dukBvSbjhJCVFOnIk0GNCOIlNBBQAgGMNHhwIJldeGd75990XCCVVVVJCgr21wV4M8QAAHOXIEetbyX/wgXT11fbUg+igBwUA4Ajvvx/oLbESTvbvD/SYEE7iDwEFABBVkycHgsk114R3/pQpgVBijOTx2FsbosdSQJk/f76uuOIKde3aVSkpKbrxxhu1devWkHOOHDmi3NxcdevWTV26dNGkSZNUVVUVcs7OnTs1fvx4derUSSkpKbr33nt17Nix5rcGABAT6usDocTlkl59NbxrXnstEEpeftne2uAMlgLK6tWrlZubqzVr1mjFihWqq6vT6NGjdejQoeA5d999t/7yl7/o9ddf1+rVq7V7925lZ2cHX/f7/Ro/fryOHj2qjz76SH/4wx/00ksv6YEHHohcqwAAjvTFF4FQ4naHf83nnweCyc0321cXnMdljDFNvXjv3r1KSUnR6tWrNWzYMFVXV+vcc8/V4sWLlZOTI0nasmWL+vXrp5KSEl111VVavny5JkyYoN27d6tHjx6SpEWLFmnu3Lnau3ev2rdvf9bPrampkcfjUXV1tRITE5taPgCghTz4oPTww9au8fvZUC3eWPn+btaPvrq6WpKUnJwsSVq/fr3q6uo0atSo4DkXX3yxevXqpZKSEklSSUmJBg4cGAwnkjRmzBjV1NTo888/b045AACHaRjGCTec/Pu/H59fQjhp3Zq8zLi+vl6zZ8/W1VdfrUsuuUSSVFlZqfbt2yspKSnk3B49eqiysjJ4zonhpOH1htcaU1tbq9ra2uDzmpqappYNALBZVZWUmmrtmsJCafhwW8pBjGpyPs3NzdWmTZv0arizm5ph/vz58ng8wUcGd3cCAMf5/e8DvSVWwsm33wZ6SwgnOFmTAsqsWbP01ltvqbCwUF6vN3g8NTVVR48e1f79+0POr6qqUup3f2JTU1NPWdXT8Dz1NH+q582bp+rq6uCjrKysKWUDAGxwwQWBYDJ9enjnDxhwfBjH6oZsaD0sBRRjjGbNmqWlS5dq1apVOv/880NeHzJkiNq1a6eVK1cGj23dulU7d+5UZmamJCkzM1MbN27Unj17guesWLFCiYmJ6t+/f6Ofm5CQoMTExJAHACB6Dh06Pr+ktDS8a15+ORBKNm2ytzbEB0tzUHJzc7V48WItW7ZMXbt2Dc4Z8Xg86tixozwej6ZPn645c+YoOTlZiYmJ+vnPf67MzExdddVVkqTRo0erf//+uv322/XYY4+psrJS999/v3Jzc5XAjRMAwNFWrJBGj7Z2zd69Uvfu9tSD+GVpmbHL5Wr0+Isvvqhp06ZJCmzUds8992jJkiWqra3VmDFj9Oyzz4YM33z11VeaOXOmioqK1LlzZ02dOlWPPvqo2rYNLy+xzBgAWtYNN0h/+Yu1a5q+iQXilZXv72btgxItBBQAsJ/fL4X598agRx6RfvUre+pB7LPy/c3djAEAIT77TBo82No1//iH9L3v2VMPWie2wQEASJL+4z8Ck16thJP6+sBQDuEEkUYPCgC0Yk3ZsXXaNOnFF20pBwgioABAK7Rrl2R1z8uPPpK+2zECsB1DPADQiixcGBjGsRJOjhwJ9LQQTtCS6EEBgFbgNLtEnNbQodKaNfbUAoSDHhQAiFP/+tfx3V7D9cYbgd4SwgmijYACAHHmt78NhJJzzw3/mn37AsEkO9u+ugArGOIBgDhhdRinU6fAPXUAJ6IHBQBiWG2t9WGcadMCvSWEEzgZPShxwu/3q7i4WBUVFUpLS1NWVpbcbne0ywJgk3fekcaNs3bNxo3SJZfYUw8QaQSUOODz+ZSXl6ddu3YFj3m9XuXn5yubAWUgrgwcKG3aZO2a+nrrwz9AtDHEE+N8Pp9ycnJCwokklZeXKycnRz6fL0qVAYgUY44P44QbTi69NHBdw7VArCGgxDC/36+8vDw1dkPqhmOzZ8+W3+9v6dIARMDGjYFwYWUr+nfeCYSS//kf++oCWgIBJYYVFxef0nNyImOMysrKVFxc3IJVAWiuqVMDwWTQoPCvadjtdcwY++oCWhJzUGJYRUVFRM8DEF1NGYpppAMViAv0oMSwtLS0iJ4HoOVVVlpfJvzMM8fnlwDxih6UGJaVlSWv16vy8vJG56G4XC55vV5lZWVFoTogdrXEsv3HHpPmzrV2zb/+JXXrFtEyAMcioMQwt9ut/Px85eTkyOVyhYQU13d/HVuwYAH7oQAW2L1sn2EcIDwM8cS47OxsFRQUqGfPniHHvV6vCgoK2AcFsMCuZfvffmt9GOfnP2cYB62byzQ2NuBwNTU18ng8qq6uVmJiYrTLcQR2kgWax+/3q3fv3qddGdcwZFpaWhr2/1s+nzRpkrU6tm6V+vSxdg0QK6x8fzPEEyfcbreGDx8e7TKAmGVl2f7Z/l/r1UsqK7P2+bH3V0XAXgzxAICav2y/YTt5lyv8cDJsGMM4wOnQgwIAavqy/U8+ka64wtpnrV4dCCc4O4avWy8CCgDI+rL97Gxp6VJrn1FXJ7Xlt27YuBFq68YQDwDo+LJ96fgy/QYnLttv29Ytlyv8cNKx4/FhHMJJ+LgRKggoAPCd0y3bT029UsbUa9Kk8P/W/uKLgVDy7beRrjL+cSNUSAQUAAiRnZ2tL7/8UoWFhcrO/kySUUXFmrCv378/EEymTbOrwvjHjVAhMQcFAE7Rtq1b0nBL17ASJ3K4ESokelAAQJL0zTfWd3udN49lwnbgRqiQCCgAWrnHHw+EkuTk8K/58stAKPnNb2wrq1VrWFF18mTlBi6XSxkZGdwINc4xxAOgVeKmfc7FjVAh0YMCoBU5dsz6ME6/fgzjRAM3QgU3CwQQ9/78Z2niRGvXLF8ujR1rTz0IHzvJxhduFggAkpKSpOpqa9ccOybx/ecc3Ai19SKgAIg7zC8BYh9zUADEhc8+sz6/JD+f+SWAU9GDAiCmjR8v/fWv1q6prpaYvgY4GwEFQExiGAeIbwzxAIgZu3dbH8b5yU8YxgFiEQEFgONNmxYIJSdtiXFGO3YEQskLL9hWFgAbMcQDwLEYxgFaL3pQADjK4cPWh3H692cYB4g3BBQAjvDb3wZCSadO4V/zl78EQsnnn9tXF4DoYIgHQFQ1ZRjH75fa8NcrIK4RUAC0OGOaFjAYwgFaD/4OAqDFrFoV6DGxEk7mz2d+CdAa0YMCwHYej1RTY+2aAwekLl3sqQeA8xFQANiGZcIAmoohHgARVVpqfZnwjTcyjAMgFD0oiBq/36/i4mJVVFQoLS1NWVlZcrvd0S4LTTR4cOCOwlbs2CFdcIE99QCIbQQURIXP51NeXp527doVPOb1epWfn6/s7OwoVgarGMYBYAeGeNDifD6fcnJyQsKJJJWXlysnJ0c+ny9KlSFc1dXWh3GSkhjGARA+ywHl/fff1w9/+EOlp6fL5XLpzTffDHl92rRpcrlcIY+xY8eGnLNv3z5NmTJFiYmJSkpK0vTp03Xw4MFmNQSxwe/3Ky8vT6aRb6mGY7Nnz5bf72/p0hCG2bMDoSQpKfxrVq0KhJJvvrGrKgDxyPIQz6FDhzR48GD95Cc/OW1X/NixY/Xiiy8GnyckJIS8PmXKFFVUVGjFihWqq6vTHXfcoRkzZmjx4sVWy0GMKS4uPqXn5ETGGJWVlam4uFjDhw9vucJwRk0Zxqmvb9p1ACA1IaCMGzdO48aNO+M5CQkJSk1NbfS1L774Qu+8847WrVunyy+/XJK0cOFCXX/99XriiSeUnp5utSTEkIqKioieB/vU10tNmbPMEA6ASLBlDkpRUZFSUlLUt29fzZw5U19//XXwtZKSEiUlJQXDiSSNGjVKbdq00dq1a+0oBw6SlpYW0fMQeYsXB3o+rISThx9mfgmAyIr4Kp6xY8cqOztb559/vnbs2KFf/vKXGjdunEpKSuR2u1VZWamUlJTQItq2VXJysiorKxt9z9raWtXW1gaf11jdkhKOkZWVJa/Xq/Ly8kbnobhcLnm9XmVlZUWhutatKcMxhw5Zu/swAIQr4gHllltuCf77wIEDNWjQIF144YUqKirSyJEjm/Se8+fP10MPPRSpEhFFbrdb+fn5ysnJkcvlCgkpru++IRcsWMB+KC2IZcIAnMj2ZcYXXHCBunfvru3bt0uSUlNTtWfPnpBzjh07pn379p123sq8efNUXV0dfJSVldldNmyUnZ2tgoIC9ezZM+S41+tVQUEB+6C0gP/5H+vLhK+7jmEcAC3H9o3adu3apa+//jo4pyAzM1P79+/X+vXrNWTIEEnSqlWrVF9fr6FDhzb6HgkJCaesBEJsy87O1sSJE9lJtoWlp0tW5x9/+aV03nm2lAMAp2U5oBw8eDDYGyJJpaWl2rBhg5KTk5WcnKyHHnpIkyZNUmpqqnbs2KH/9b/+ly666CKNGTNGktSvXz+NHTtWd955pxYtWqS6ujrNmjVLt9xyCyt4Whm3281S4hbCMA6AWGN5iOeTTz7RZZddpssuu0ySNGfOHF122WV64IEH5Ha79dlnn+mGG25Qnz59NH36dA0ZMkTFxcUhPSCvvPKKLr74Yo0cOVLXX3+9fvCDH+h3v/td5FoFQHv3Wh/GkRjGAeAMLtPYUgqHq6mpkcfjUXV1tRITE6NdDuAoU6dK//3f1q5ZtUoaMcKeegCggZXvb24WCMQJhnEAxBNuFgjEsLo6hnEAxCcCChCDnn8+EEratw//mvx8ggmA2MEQDxBDmjKMU1trLcgAgBMQUIAYwPwSAK0NQzyAQ334ofX5JbfcwjAOgPhADwrgMG3bSn6/tWsqKqTT3CkCAGISAQVwCIZxAOA4hniAKKqstD6Mk5TEMA6A+EdAAaLgZz8LhJLv7qEZlrVrA6Hkm2/sqwsAnIIhHqAFMYwDAOGhBwWwWW0tu70CgFUEFMAm/+//BUJJhw7hX1NQ4FdhYZEWL16ioqIi+a0u5wGAOMEQDxBhTRnGOXZMWrbMp7y8PO3atSt43Ov1Kj8/X9nZ2RGsEACcjx4UIAKMad4wzrJlPuXk5ISEE0kqLy9XTk6OfD5fBKsFAOcjoADN8MEHgVDSxsL/SQ8+GDq/xO/3Ky8vT6aRCScNx2bPns1wD4BWhSEeoAlSU6WqKmvX7N8veTynHi8uLj6l5+RExhiVlZWpuLhYw4cPt/ahABCjCCiABXYsE66oqAjrfcI9DwDiAUM8wFns3Gl9fsno0eEvE04Lc7e2cM8DgHhAQAFO49ZbA6HkvPPCv+Yf/wiEknffDf+arKwseb1euU6TgFwulzIyMpSVlRX+mwJAjGOIBzhJS+/26na7lZ+fr5ycHLlcrpDJsg2hZcGCBXK73U3/EACIMfSgAJK+/db6MI7bHbndXrOzs1VQUKCePXuGHPd6vSooKGAfFACtjss0trbR4WpqauTxeFRdXa3ExMRol4MY9tRT0pw51q55993AHBM7+P1+FRcXq6KiQmlpacrKyqLnBEDcsPL9zRAPWqWmDOPU1zftOivcbjdLiQFABBS0IsZY21DtxOsAAC2LOSiIe3/7m/XdXp98krsJA0A00YOCuNWuXeAmfFYcOiR16mRPPQCA8BFQEPNOnlg6YsRwy+9BTwkAOAsBBTHN5/MpLy9Pu3Z1kLTN0rU/+pH06qv21AUAaB4CCmKWz+fTpEmdJJVZuu6rr6ReveypCQAQGQQUxKTAcl9rm5cxjAMAsYNVPIgZ1dXWd3tNTq5lNQ4AxCACChzvoYcCoSQpycpVP5Dk0m9/67OnKACArRjigWM1bdfW0IvS0tIiUgsAoGXRgwJH8futD+MEuHRiOHG5XMrIyFBWVlYkywMAtBACChxh1apAKGlroU9v5sy/y+VqI5cr9I+x67t0s2DBAm60BwAxioCCqLrwwkAwGTky/GuOHAlMen322X9TQUGBevbsGfK61+tVQUGBsrOtrfIBADiHy5jYW99g5XbNcKamzC853Z/Uk3eSzcrKoucEABzIyvc3k2TRYsrKrG+Qdtdd0nPPnfkct9ut4cOHN7kuAIDzEFBguwcflB5+2No1FRVSaqo99SA+0HMGxDcCCmwTyWEc4ETH78G0K3jM6/UqPz+fuUdAnGCSLCLqwAHry4Tvu0/s9oqw+Xw+5eTkhIQTSSovL1dOTo58PjbnA+IBAQUR8corgVBiZc5yaWkglMyfb19diC9+v195eXlqbG5/w7HZs2fL7/e3dGkAIowhHjRLcrL0zTfWrqGnBE1VXFx8Ss/JiYwxKisrU3FxMROngRhHDwosO3G313DDyfjxDOOg+SoqKiJ6HgDnIqAgbB9+aH2315KSQCh56y376kLrEe69lbgHExD7GOLBWY0eLa1YYe2aY8ckVnwi0rKysuT1elVeXt7oPBSXyyWv18s9mIA4QA8KTqthGCfccNKjx/FhHMIJ7OB2u5Wfny/p+D2XGnAPJiC+EFAQYscO68uEX3stEEoqK+2rq7Xw+/0qKirSkiVLVFRUxGqURmRnZ3MPJqAV4F48kCTdc4/0f/6PtWsOHJC6dLGnntaIzcesYSdZIPZY+f4moLRy7PbqDA2bj538v2PDsAU9AwDigZXvb4Z4WqFvvrE+jPPIIywTtgubjwHAqQgorcj//b+BUJKcHP41u3YFQsmvfmVfXa2dlc3HAKC1YJlxK8AwjrOx+RgAnMpyD8r777+vH/7wh0pPT5fL5dKbb74Z8roxRg888IDS0tLUsWNHjRo1Stu2bQs5Z9++fZoyZYoSExOVlJSk6dOn6+DBg81qCELV1VkfxrnlFoZxooHNxwDgVJYDyqFDhzR48GA988wzjb7+2GOP6emnn9aiRYu0du1ade7cWWPGjNGRI0eC50yZMkWff/65VqxYobfeekvvv/++ZsyY0fRWIGjlykAoad8+/Gv+/vdAKFmyxL66cHoNm4+dvK9HA5fLpYyMDDYfA9C6mGaQZJYuXRp8Xl9fb1JTU83jjz8ePLZ//36TkJBglixZYowxZvPmzUaSWbduXfCc5cuXG5fLZcrLy8P63OrqaiPJVFdXN6f8uJKX19D3Ef6jvj7aVaPBG2+8YVwul3G5XEZS8NFw7I033oh2iQDQbFa+vyM6Sba0tFSVlZUaNWpU8JjH49HQoUNVUlIiSSopKVFSUpIuv/zy4DmjRo1SmzZttHbt2kbft7a2VjU1NSEPBGJGwzDOd5trnlWfPscjSlPmpsAebD4GAKEiOkm28rutRHv06BFyvEePHsHXKisrlZKSElpE27ZKTk4OnnOy+fPn66GHHopkqTGtrEzq1cvaNX/+s/TDH9pTDyIjOztbEydOZPMxAFCMrOKZN2+e5syZE3xeU1OjjIyMKFYUHQsXSr/4hbVrDh+WOnSwpx5Entvt1vDhw6NdBgBEXUQDSmpqqiSpqqoqZMVBVVWVLr300uA5e/bsCbnu2LFj2rdvX/D6kyUkJCghISGSpcaUWbOk08xJPq3WuhKH7c8BID5EdA7K+eefr9TUVK1cuTJ4rKamRmvXrlVmZqYkKTMzU/v379f69euD56xatUr19fUaOnRoJMuJaYcPB+5z43KFH06WLm3dy4R9Pp969+6tESNG6NZbb9WIESPUu3dv+Xy+aJcGALDIcg/KwYMHtX379uDz0tJSbdiwQcnJyerVq5dmz56tRx55RN/73vd0/vnn69e//rXS09N14403SpL69eunsWPH6s4779SiRYtUV1enWbNm6ZZbblF6enrEGharNmyQLrvM2jXffCMlJdlRTew43b1sysvLlZOTw0RTAIg1VpcIFRYWhiyDbHhMnTrVGBNYavzrX//a9OjRwyQkJJiRI0earVu3hrzH119/bSZPnmy6dOliEhMTzR133GEOHDgQdg3xuMz48cetLRH2eKJdsXMcO3bMeL3eRv9c6ruluhkZGebYsWPRLhUAWjUr39/czTiKjh2TBg2Svvgi/GsWLZJ++lP7aoqW5swdKSoq0ogRI856XmFhIRNQASCKrHx/x8QqnnhTWipdcIG1a77+2tpN/mKJz+dTXl5eyA3zvF6v8vPzwxqW4V42ABB/uJtxC/rjHwOTXsMNJ9nZUn19YFAnnsNJTk7OKXfzbZg7Es4EV+5lAwDxhyEemxkjXX+99M474V/z2mvSzTfbV5NT+P1+9e7d+5Rw0sDlcsnr9aq0tPSMwz0N71NeXn7KJFkr7wMAsJeV7296UGyyd2+gt6RNm/DDyc6dgUDTGsKJJBUXF582nEiBO2OXlZWpuLj4jO/jdruV/91e/yffcK/h+YIFCwgnABBDCCgR9u67gWBy0m7+p3X55YHJssZIrW1z3EjOHeFeNgAQX5gkGyF33SU9/3z45z/9tPTzn9tXTyyI9NwR7mUDAPGDOSjNcOiQlJgYmMgark2bpAED7KspljB3BABaF+ag2OyTTwLDOF26hBdOzj1XOnIkMIxDODmOuSMAgNMhoFjwyCOBYHLFFeGdP3duIJTs2SO14nsdnhFzRwAAjWGI5yzq6qS+fQObq4WruFj6wQ/sqykecRdiAIh/7CQbAdu2SX36WLtm/37J47GlnLjndrvZhh4AEMQQz0kalgmHG06mTDl+Cz/CCQAAkUFA+U59vZSbK40dG975S5cGQsnLL9tbFwAArRFDPN8pKpKeffbs55WXS+nptpcDAECrRg/Kd6qrT/9aVpbk9wd6TAgnAADYj4DynQkTpDFjQo89/3wglLz/fuCeOgAAoGUwxPOddu2k5csDN/lLTpba8l8GAICo4Wv4BFZu8gcAAOzDwAUAAHAcAgoAAHAcAgoAAHAcAgoAAHAcAgoAAHAcAgoAAHAclhnHAL/fr+LiYlVUVCgtLU1ZWVlyu93RLgsAANsQUBzO5/MpLy9Pu3btCh7zer3Kz89XdnZ2FCsDAMA+DPE4mM/nU05OTkg4kaTy8nLl5OTI5/NFqTIAAOxFQHEov9+vvLw8GWNOea3h2OzZs+X3+1u6NAAAbEdAcaji4uJTek5OZIxRWVmZiouLW7AqAABaBgHFoSoqKiJ6HgAAsYRJsg6VlpYW0fMAJ2KFGoDTIaA4VFZWlrxer8rLyxudh+JyueT1epWVlRWF6mIPX4TOwwo1AGfCEI9Dud1u5efnSwqEkRM1PF+wYAFfsmHw+Xzq3bu3RowYoVtvvVUjRoxQ7969WQUVRaxQA3A2BBQHy87OVkFBgXr27Bly3Ov1qqCggL9lhoEvQudhhRqAcLhMY78lHK6mpkYej0fV1dVKTEyMdjm2Y3iiafx+v3r37n3a1VANw2SlpaVN+u/Jz6VpioqKNGLEiLOeV1hYqOHDh9tfEIAWY+X7mzkoMcDtdvOLugmsLNW2+t+X+RNNxwo1AOFgiAdxy64vQoaNmocVagDCQUBB3LLji5D5E83XsELt5MnfDVwulzIyMlihBrRyBBTELTu+CNnht/lYoQYgHAQUxC07vgiZPxEZrFADcDYEFMS1SH8RMn8icrKzs/Xll1+qsLBQixcvVmFhoUpLSwknACSxzBitRKSWBDcsXT7bDr9NXboMAPGMZcbASSK1VLth2CgnJ0culyskpDB/AgAihyGe0/D7/SoqKtKSJUtUVFTEqgwEMX8CAOzHEE8j2IQL4WAnWQCwxsr3NwHlJA2bcJ38n6Wh+56/IQMA0DRWvr8Z4jkBm3ABAOAMBJQTsAkXAADOQEA5AZtwAQDgDASUE7AJFwAAzkBAOQE3MQMAwBkIKCfgJmYAADgDAeUkbMIFAED0RTyg/Od//qdcLlfI4+KLLw6+fuTIEeXm5qpbt27q0qWLJk2apKqqqkiX0SzcxAxoGnZgBhApttyLZ8CAAXrvvfeOf0jb4x9z99136+2339brr78uj8ejWbNmKTs7Wx9++KEdpVjCzqBA07EDM4BIsiWgtG3bVqmpqaccr66u1gsvvKDFixfr2muvlSS9+OKL6tevn9asWaOrrrrKjnLCwi9XoOlOtwNzeXm5cnJyGB4FYJktc1C2bdum9PR0XXDBBZoyZYp27twpSVq/fr3q6uo0atSo4LkXX3yxevXqpZKSktO+X21trWpqakIekdTwy/XkTdoafrn6fL6Ifh4QT9iBGYAdIh5Qhg4dqpdeeknvvPOOnnvuOZWWliorK0sHDhxQZWWl2rdvr6SkpJBrevToocrKytO+5/z58+XxeIKPjIyMiNXLL1egediBGYAdIj7EM27cuOC/Dxo0SEOHDtV5552nP/3pT+rYsWOT3nPevHmaM2dO8HlNTU3EQoqVX67Dhw+PyGcC8YQdmAHYwfZlxklJSerTp4+2b9+u1NRUHT16VPv37w85p6qqqtE5Kw0SEhKUmJgY8ogUfrkCzcMOzADsYHtAOXjwoHbs2KG0tDQNGTJE7dq108qVK4Ovb926VTt37lRmZqbdpTSKX65A87ADMwA7RDyg/Md//IdWr16tL7/8Uh999JFuuukmud1uTZ48WR6PR9OnT9ecOXNUWFio9evX64477lBmZmbUVvDwyxVoHnZgBmCHiAeUXbt2afLkyerbt69uvvlmdevWTWvWrNG5554rSXrqqac0YcIETZo0ScOGDVNqampUV8nwyxVoPnZgBhBpLtPY8hWHq6mpkcfjUXV1dcTmozS2D0pGRoYWLFjAL1cgTGx2COBMrHx/E1BOwC9XAADsY+X725adZGOV2+1mKTEAAA7A3YwBAIDjEFAAAIDjEFAAAIDjEFAAAIDjEFAAAIDjEFAAAIDjEFAAAIDjEFAAAIDjEFAAAIDjxOROsg2789fU1ES5EgAAEK6G7+1w7rITkwHlwIEDkgI38wMAALHlwIED8ng8ZzwnJm8WWF9fr927d6tr165yuVzB4zU1NcrIyFBZWVlEbyLoFPHcvnhumxTf7aNtsSue2xfPbZNit33GGB04cEDp6elq0+bMs0xisgelTZs28nq9p309MTExpn5gVsVz++K5bVJ8t4+2xa54bl88t02KzfadreekAZNkAQCA4xBQAACA48RVQElISNCDDz6ohISEaJdii3huXzy3TYrv9tG22BXP7Yvntknx3z4pRifJAgCA+BZXPSgAACA+EFAAAIDjEFAAAIDjEFAAAIDjxFxA2bdvn6ZMmaLExEQlJSVp+vTpOnjw4BmvOXLkiHJzc9WtWzd16dJFkyZNUlVVVcg569at08iRI5WUlKRzzjlHY8aM0aeffmpnU05hV9sk6aWXXtKgQYPUoUMHpaSkKDc3165mNMrOtknS119/La/XK5fLpf3799vQgjOzo32ffvqpJk+erIyMDHXs2FH9+vVTfn6+3U2RJD3zzDPq3bu3OnTooKFDh+rjjz8+4/mvv/66Lr74YnXo0EEDBw7UX//615DXjTF64IEHlJaWpo4dO2rUqFHatm2bnU04rUi2ra6uTnPnztXAgQPVuXNnpaen68c//rF2795tdzMaFemf24nuuusuuVwuLViwIMJVh8+O9n3xxRe64YYb5PF41LlzZ11xxRXauXOnXU04rUi37eDBg5o1a5a8Xq86duyo/v37a9GiRXY2IfJMjBk7dqwZPHiwWbNmjSkuLjYXXXSRmTx58hmvueuuu0xGRoZZuXKl+eSTT8xVV11lvv/97wdfP3DggElOTjbTpk0zW7ZsMZs2bTKTJk0yPXr0MEePHrW7SUF2tM0YY5588kmTnp5uXnnlFbN9+3bz6aefmmXLltnZlFPY1bYGEydONOPGjTOSzDfffGNDC87Mjva98MIL5he/+IUpKioyO3bsMH/84x9Nx44dzcKFC21ty6uvvmrat29vfv/735vPP//c3HnnnSYpKclUVVU1ev6HH35o3G63eeyxx8zmzZvN/fffb9q1a2c2btwYPOfRRx81Ho/HvPnmm+bTTz81N9xwgzn//PPN4cOHbW3LySLdtv3795tRo0aZ1157zWzZssWUlJSYK6+80gwZMqQlm2WMsefn1sDn85nBgweb9PR089RTT9ncksbZ0b7t27eb5ORkc++995q///3vZvv27WbZsmWnfU+72NG2O++801x44YWmsLDQlJaWmueff9643e4W/93fHDEVUDZv3mwkmXXr1gWPLV++3LhcLlNeXt7oNfv37zft2rUzr7/+evDYF198YSSZkpISY4wx69atM5LMzp07g+d89tlnRpLZtm2bTa0JZVfb9u3bZzp27Gjee+89extwBna1rcGzzz5rrrnmGrNy5cqoBBS723ein/3sZ2bEiBGRK74RV155pcnNzQ0+9/v9Jj093cyfP7/R82+++WYzfvz4kGNDhw41P/3pT40xxtTX15vU1FTz+OOPB1/fv3+/SUhIMEuWLLGhBacX6bY15uOPPzaSzFdffRWZosNkV9t27dplevbsaTZt2mTOO++8qAUUO9r3ox/9yNx22232FGyBHW0bMGCAefjhh0PO+bd/+zfzq1/9KoKV2yumhnhKSkqUlJSkyy+/PHhs1KhRatOmjdauXdvoNevXr1ddXZ1GjRoVPHbxxRerV69eKikpkST17dtX3bp10wsvvKCjR4/q8OHDeuGFF9SvXz/17t3b1jY1sKttK1asUH19vcrLy9WvXz95vV7dfPPNKisrs7dBJ7CrbZK0efNmPfzww/rv//7vs954yi52tu9k1dXVSk5OjlzxJzl69KjWr18fUlebNm00atSo09ZVUlIScr4kjRkzJnh+aWmpKisrQ87xeDwaOnToGdsaaXa0rTHV1dVyuVxKSkqKSN3hsKtt9fX1uv3223XvvfdqwIAB9hQfBjvaV19fr7ffflt9+vTRmDFjlJKSoqFDh+rNN9+0rR2Nsetn9/3vf19//vOfVV5eLmOMCgsL9Y9//EOjR4+2pyE2iKmAUllZqZSUlJBjbdu2VXJysiorK097Tfv27U/5ZdGjR4/gNV27dlVRUZFefvlldezYUV26dNE777yj5cuXq23blrmfol1t++c//6n6+nr95je/0YIFC1RQUKB9+/bpuuuu09GjR21pS2N12tG22tpaTZ48WY8//rh69eplS+3hsKt9J/voo4/02muvacaMGRGpuzH/+te/5Pf71aNHj7DrqqysPOP5Df+08p52sKNtJzty5Ijmzp2ryZMnt+gN3Oxq23/913+pbdu2+sUvfhH5oi2wo3179uzRwYMH9eijj2rs2LH629/+pptuuknZ2dlavXq1PQ1phF0/u4ULF6p///7yer1q3769xo4dq2eeeUbDhg2LfCNs4oiAct9998nlcp3xsWXLFts+//Dhw5o+fbquvvpqrVmzRh9++KEuueQSjR8/XocPH27We0e7bfX19aqrq9PTTz+tMWPG6KqrrtKSJUu0bds2FRYWNuu9o922efPmqV+/frrttttsef9ot+9EmzZt0sSJE/Xggw/G1N+AWpO6ujrdfPPNMsboueeei3Y5zbZ+/Xrl5+frpZdeksvlinY5EVdfXy9Jmjhxou6++25deumluu+++zRhwoTYm0zaiIULF2rNmjX685//rPXr1+vJJ59Ubm6u3nvvvWiXFraW6R44i3vuuUfTpk074zkXXHCBUlNTtWfPnpDjx44d0759+5SamtrodampqTp69Kj2798f8rfVqqqq4DWLFy/Wl19+qZKSkuAwweLFi3XOOedo2bJluuWWW2K2bWlpaZKk/v37B18/99xz1b1792bPVI9221atWqWNGzeqoKBAUmCliCR1795dv/rVr/TQQw81sWUB0W5fg82bN2vkyJGaMWOG7r///ia1JVzdu3eX2+0+ZbVUY3U1SE1NPeP5Df+sqqoK/nlseH7ppZdGsPozs6NtDRrCyVdffaVVq1a1aO+JZE/biouLtWfPnpDeSb/fr3vuuUcLFizQl19+GdlGnIEd7evevbvatm0b8rtRkvr166cPPvgggtWfmR1tO3z4sH75y19q6dKlGj9+vCRp0KBB2rBhg5544olThoccK8pzYCxpmIz4ySefBI+9++67YU1GLCgoCB7bsmVLyGTEp59+2qSmppr6+vrgOXV1daZz587mlVdesak1oexq29atW42kkEmyX3/9tWnTpo159913bWpNKLvatn37drNx48bg4/e//72RZD766KMWnYVvV/uMMWbTpk0mJSXF3HvvvfY14CRXXnmlmTVrVvC53+83PXv2POOEvQkTJoQcy8zMPGWS7BNPPBF8vbq6OmqTZCPZNmOMOXr0qLnxxhvNgAEDzJ49e+wpPAyRbtu//vWvkP+/Nm7caNLT083cuXPNli1b7GvIadjxs8vMzDxlkuyNN9541hV4kRbptlVXVxtJ5q9//WvIOTNmzDDXXXddhKu3T0wFFGMCyzkvu+wys3btWvPBBx+Y733veyF/mHbt2mX69u1r1q5dGzx21113mV69eplVq1aZTz75xGRmZprMzMzg61988YVJSEgwM2fONJs3bzabNm0yt912m/F4PGb37t0x3TZjAktwBwwYYD788EOzceNGM2HCBNO/f/8WX0JtR9tOVFhYGNVlxpFu38aNG825555rbrvtNlNRURF82P0l+Oqrr5qEhATz0ksvmc2bN5sZM2aYpKQkU1lZaYwx5vbbbzf33Xdf8PwPP/zQtG3b1jzxxBPmiy++MA8++GCjy4yTkpLMsmXLzGeffWYmTpwYtWXGkWzb0aNHzQ033GC8Xq/ZsGFDyM+ptrY2ptvWmGiu4rGjfT6fz7Rr18787ne/M9u2bTMLFy40brfbFBcXx3zbrrnmGjNgwABTWFho/vnPf5oXX3zRdOjQwTz77LMt2rbmiLmA8vXXX5vJkyebLl26mMTERHPHHXeYAwcOBF8vLS01kkxhYWHw2OHDh83PfvYzc84555hOnTqZm266yVRUVIS879/+9jdz9dVXG4/HY8455xxz7bXXnnG5px3salt1dbX5yU9+YpKSkkxycrK56aabQpZUtwS72naiaAYUO9r34IMPGkmnPM477zzb27Nw4ULTq1cv0759e3PllVeaNWvWBF+75pprzNSpU0PO/9Of/mT69Olj2rdvbwYMGGDefvvtkNfr6+vNr3/9a9OjRw+TkJBgRo4cabZu3Wp7OxoTybY1/Fwbe5z4s24pkf65nSyaAcUYe9r3wgsvmIsuush06NDBDB482Lz55pt2N6NRkW5bRUWFmTZtmklPTzcdOnQwffv2NU8++WTISIHTuYz5buAeAADAIRyxigcAAOBEBBQAAOA4BBQAAOA4BBQAAOA4BBQAAOA4BBQAAOA4BBQAAOA4BBQAAOA4BBQAAOA4BBQAAOA4BBQAAOA4BBQAAOA4/x/Fa8XxhcyXjQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=0)\n",
        "\n",
        "# instantiate the model\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# fit the model with data\n",
        "logreg.fit(X_train,y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "cnf_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWTZkzUgR9fl",
        "outputId": "49bf91c8-d769-4872-f532-6a73f61592dd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[13,  0,  0],\n",
              "       [ 0, 15,  1],\n",
              "       [ 0,  0,  9]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Confusion Matrix**\n",
        "A confusion matrix is a table used to evaluate the performance of a classification model on a set of data for which the true values are known. It is particularly useful in supervised learning to understand how well a model is predicting outcomes across different classes. The matrix compares the actual target values with those predicted by the machine learning model, providing insight into the types of errors the model is making.\n",
        "\n",
        "The confusion matrix is typically organized with actual classes in rows and predicted classes in columns, although the layout can vary. For a binary classification problem (where there are only two classes, usually labeled as positive and negative), the confusion matrix consists of four different components:\n",
        "\n",
        "1. **True Positives (TP)**: The number of positive instances correctly predicted as positive.\n",
        "2. **True Negatives (TN)**: The number of negative instances correctly predicted as negative.\n",
        "3. **False Positives (FP)**: The number of negative instances incorrectly predicted as positive (also known as Type I error).\n",
        "4. **False Negatives (FN)**: The number of positive instances incorrectly predicted as negative (also known as Type II error).\n",
        "\n",
        "From these four components, various metrics can be calculated to evaluate the model's performance, including:\n",
        "\n",
        "- **Accuracy**: Measures the proportion of correct predictions (both positive and negative) among all predictions. Calculated as (TP + TN) / (TP + TN + FP + FN).\n",
        "- **Precision**: Measures the proportion of correct positive predictions in all positive predictions made. It is calculated as TP / (TP + FP).\n",
        "- **Recall** (or Sensitivity): Measures the proportion of actual positives correctly identified. It is calculated as TP / (TP + FN).\n",
        "- **F1 Score**: A harmonic mean of precision and recall, providing a balance between them. It is calculated as 2 * (Precision * Recall) / (Precision + Recall).\n",
        "\n",
        "For multi-class classification problems, the confusion matrix expands to accommodate the additional classes, resulting in a larger matrix. Each row represents the instances of an actual class, while each column represents the instances of a predicted class. The diagonal elements of the matrix (top left to bottom right) represent the number of instances correctly predicted for each class, while the off-diagonal elements indicate misclassifications.\n",
        "\n",
        "The confusion matrix is a powerful tool for diagnostic purposes, allowing analysts to identify which classes are being confused with one another and to focus on improving the model's performance in specific areas."
      ],
      "metadata": {
        "id": "_Wv4c0huXlhF"
      }
    }
  ]
}